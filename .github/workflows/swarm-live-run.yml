name: swarm-live-run

on:
  workflow_dispatch:
    inputs:
      request_id:
        description: "Swarm run id from CLI"
        required: true
        type: string
      expected_commit_sha:
        description: "Pinned commit required by caller"
        required: true
        type: string
      source_backend:
        description: "Input backend selector"
        required: false
        default: "artifact"
        type: string
      output_backend:
        description: "Output backend selector"
        required: false
        default: "artifact"
        type: string
      agent_image:
        description: "Agent image metadata"
        required: false
        default: "ghcr.io/example/swarm-agent:latest"
        type: string
      agent_step:
        description: "Agent step metadata"
        required: false
        default: "echo swarm live run"
        type: string
      checkpoint_in:
        description: "Optional checkpoint locator"
        required: false
        default: ""
        type: string
      state_cap_in:
        description: "Optional state capability token from previous step"
        required: false
        default: ""
        type: string
      net_cap_in:
        description: "Optional net capability token from previous step"
        required: false
        default: ""
        type: string
      route_mode:
        description: "Network route mode: direct or client_exit"
        required: false
        default: "direct"
        type: string

jobs:
  live-run:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: read
      actions: read

    steps:
      - name: Validate expected commit pin
        shell: bash
        run: |
          set -euo pipefail
          expected="${{ inputs.expected_commit_sha }}"
          actual="${{ github.sha }}"
          if [ "${expected}" != "${actual}" ]; then
            echo "::error::expected_commit_sha mismatch expected=${expected} actual=${actual}"
            exit 1
          fi

      - name: Build capability context
        shell: bash
        run: |
          set -euo pipefail
          run_id="${{ inputs.request_id }}"
          mkdir -p artifact workspace_state incoming runtime
          export RUN_ID="${run_id}"
          export STATE_CAP_IN="${{ inputs.state_cap_in }}"
          export NET_CAP_IN="${{ inputs.net_cap_in }}"
          python3 - <<'PY'
          import base64
          import hashlib
          import json
          import os
          from pathlib import Path

          run_id = os.environ["RUN_ID"]
          state_cap_in = os.environ.get("STATE_CAP_IN", "").strip()
          net_cap_in = os.environ.get("NET_CAP_IN", "").strip()

          def decode_token(token: str) -> dict:
              padding = "=" * (-len(token) % 4)
              payload = base64.urlsafe_b64decode(token + padding)
              return json.loads(payload.decode())

          def encode_token(obj: dict) -> str:
              payload = json.dumps(obj, separators=(",", ":")).encode()
              return base64.urlsafe_b64encode(payload).decode().rstrip("=")

          if state_cap_in:
              state_current = decode_token(state_cap_in)
          else:
              state_seed = hashlib.sha256(f"seed-state::{run_id}".encode()).hexdigest()
              state_current = {
                  "version": 1,
                  "kind": "state_cap",
                  "state_id": f"state-{run_id}-seed",
                  "ratchet_step": 0,
                  "chain_key": state_seed,
              }

          if net_cap_in:
              net_current = decode_token(net_cap_in)
          else:
              net_seed = hashlib.sha256(f"seed-net::{run_id}".encode()).hexdigest()
              net_current = {
                  "version": 1,
                  "kind": "net_cap",
                  "state_id": state_current["state_id"],
                  "ratchet_step": state_current["ratchet_step"],
                  "chain_key": net_seed,
              }

          def derive(chain_key: str, context: str) -> str:
              return hashlib.sha256(f"{chain_key}::{context}".encode()).hexdigest()

          state_next = {
              "version": 1,
              "kind": "state_cap",
              "state_id": f"state-{run_id}",
              "ratchet_step": int(state_current["ratchet_step"]) + 1,
              "chain_key": derive(state_current["chain_key"], f"run:{run_id}"),
          }
          net_next = {
              "version": 1,
              "kind": "net_cap",
              "state_id": state_next["state_id"],
              "ratchet_step": state_next["ratchet_step"],
              "chain_key": derive(net_current["chain_key"], f"run:{run_id}"),
          }

          Path("runtime/state_cap_next.token").write_text(encode_token(state_next), encoding="utf-8")
          Path("runtime/net_cap_next.token").write_text(encode_token(net_next), encoding="utf-8")
          Path("runtime/state_chain_key_current.txt").write_text(state_current["chain_key"], encoding="utf-8")
          Path("runtime/state_chain_key_next.txt").write_text(state_next["chain_key"], encoding="utf-8")
          Path("runtime/state_id_next.txt").write_text(state_next["state_id"], encoding="utf-8")
          Path("runtime/ratchet_step_next.txt").write_text(str(state_next["ratchet_step"]), encoding="utf-8")
          Path("artifact/capability_meta.json").write_text(
              json.dumps(
                  {
                      "state_current": {
                          "state_id": state_current["state_id"],
                          "ratchet_step": state_current["ratchet_step"],
                      },
                      "state_next": {
                          "state_id": state_next["state_id"],
                          "ratchet_step": state_next["ratchet_step"],
                      },
                      "net_current": {
                          "ratchet_step": net_current["ratchet_step"],
                      },
                      "net_next": {
                          "ratchet_step": net_next["ratchet_step"],
                      },
                  },
                  indent=2,
              ),
              encoding="utf-8",
          )
          PY

      - name: Restore encrypted prior bundle (optional)
        shell: bash
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          checkpoint="${{ inputs.checkpoint_in }}"
          if [ -z "${checkpoint}" ]; then
            echo "No checkpoint_in provided; starting new state episode."
            echo 0 > workspace_state/counter.txt
            exit 0
          fi

          if [[ "${checkpoint}" =~ ^gh-artifact://([0-9]+)/(.+)$ ]]; then
            source_run_id="${BASH_REMATCH[1]}"
            source_artifact="${BASH_REMATCH[2]}"
          else
            echo "::error::checkpoint_in must match gh-artifact://<run_id>/<artifact_name>"
            exit 1
          fi

          gh run download "${source_run_id}" \
            -R "${GITHUB_REPOSITORY}" \
            -n "${source_artifact}" \
            -D incoming

          encrypted_path="$(find incoming -type f -name 'state_bundle.tar.enc' | head -n 1 || true)"
          if [ -z "${encrypted_path}" ]; then
            echo "::error::state_bundle.tar.enc not found in downloaded artifact"
            exit 1
          fi

          current_key="$(cat runtime/state_chain_key_current.txt)"
          openssl enc -d -aes-256-cbc -pbkdf2 \
            -in "${encrypted_path}" \
            -out state_bundle.tar \
            -pass "pass:${current_key}"

          tar -xf state_bundle.tar -C workspace_state

      - name: Checkout repo (proxy mode)
        if: inputs.route_mode == 'client_exit'
        uses: actions/checkout@v4

      - name: Install Rust toolchain (proxy mode)
        if: inputs.route_mode == 'client_exit'
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust build (proxy mode)
        if: inputs.route_mode == 'client_exit'
        uses: Swatinem/rust-cache@v2

      - name: Build and validate proxy tunnel (proxy mode)
        if: inputs.route_mode == 'client_exit'
        shell: bash
        run: |
          set -euo pipefail

          cargo build -p swarm-proxy --release
          BIN="target/release/swarm-proxy"

          export BROKER_ADDR="127.0.0.1:18787"
          export SESSION_ID="live-run-${{ inputs.request_id }}"
          TARGET_PORT="19090"

          TMP_ROOT="$(mktemp -d)"
          EXPECTED_PAYLOAD="swarm-proxy-live-ok-${{ inputs.request_id }}"
          echo "${EXPECTED_PAYLOAD}" > "${TMP_ROOT}/ping.txt"

          cleanup() {
            kill "${PROVIDER_PID:-}" "${BROKER_PID:-}" "${HTTP_PID:-}" 2>/dev/null || true
          }
          trap cleanup EXIT

          python3 -m http.server "${TARGET_PORT}" --bind 127.0.0.1 --directory "${TMP_ROOT}" >proxy_http.log 2>&1 &
          HTTP_PID=$!

          "${BIN}" broker --listen "${BROKER_ADDR}" >proxy_broker.log 2>&1 &
          BROKER_PID=$!

          TICKET_JSON="$("${BIN}" --json ticket --session-id "${SESSION_ID}" --broker "${BROKER_ADDR}")"
          TOKEN="$(python3 -c 'import json,sys; print(json.load(sys.stdin)["token"])' <<<"${TICKET_JSON}")"

          "${BIN}" provider --broker "${BROKER_ADDR}" --session-id "${SESSION_ID}" --token "${TOKEN}" >proxy_provider.log 2>&1 &
          PROVIDER_PID=$!

          PROXIED_OK=false
          for i in $(seq 1 30); do
            if curl -fsS \
              --proxy "http://${BROKER_ADDR}" \
              --proxy-user "${SESSION_ID}:${TOKEN}" \
              "http://127.0.0.1:${TARGET_PORT}/ping.txt" > proxied.txt 2>/dev/null; then
              PROXIED_OK=true
              break
            fi
            sleep 1
          done

          if [ "${PROXIED_OK}" != "true" ]; then
            echo "::error::Proxy tunnel validation failed â€” no successful proxied request"
            exit 1
          fi

          diff -u <(echo "${EXPECTED_PAYLOAD}") proxied.txt

          export CERT_HASH="$(sha256sum <<<"${TICKET_JSON}" | awk '{print $1}')"

          python3 - <<'PY'
          import json, os
          from pathlib import Path
          evidence = {
              "proxy_validated": True,
              "route_mode": "client_exit",
              "session_id": os.environ.get("SESSION_ID", ""),
              "broker_addr": os.environ.get("BROKER_ADDR", ""),
              "ticket_cert_hash": "sha256:" + os.environ.get("CERT_HASH", ""),
              "payload_match": True,
          }
          Path("artifact/proxy_evidence.json").write_text(
              json.dumps(evidence, indent=2) + "\n", encoding="utf-8"
          )
          PY

          echo "Proxy tunnel validation passed"

      - name: Upload proxy logs on failure
        if: inputs.route_mode == 'client_exit' && failure()
        uses: actions/upload-artifact@v4
        with:
          name: proxy-logs-${{ inputs.request_id }}
          path: |
            proxy_broker.log
            proxy_provider.log
            proxy_http.log

      - name: Execute step and create encrypted next bundle
        shell: bash
        run: |
          set -euo pipefail
          run_id="${{ inputs.request_id }}"
          counter_file="workspace_state/counter.txt"
          if [ ! -f "${counter_file}" ]; then
            echo 0 > "${counter_file}"
          fi
          counter="$(cat "${counter_file}")"
          counter="$((counter + 1))"
          echo "${counter}" > "${counter_file}"
          printf '%s\n' "${run_id}" >> workspace_state/history.log

          tar -cf state_bundle.tar -C workspace_state .
          next_key="$(cat runtime/state_chain_key_next.txt)"
          openssl enc -aes-256-cbc -pbkdf2 \
            -in state_bundle.tar \
            -out artifact/state_bundle.tar.enc \
            -pass "pass:${next_key}"

      - name: Emit contract artifacts
        shell: bash
        run: |
          set -euo pipefail
          run_id="${{ inputs.request_id }}"
          state_id_next="$(cat runtime/state_id_next.txt)"
          ratchet_step_next="$(cat runtime/ratchet_step_next.txt)"
          state_cap="$(cat runtime/state_cap_next.token)"
          net_cap="$(cat runtime/net_cap_next.token)"
          bundle_artifact_name="state-bundle-${run_id}"
          bundle_ref="gh-artifact://${GITHUB_RUN_ID}/${bundle_artifact_name}"
          bundle_hash="sha256:$(sha256sum artifact/state_bundle.tar.enc | awk '{print $1}')"
          export RUN_ID="${run_id}"
          export STATE_ID_NEXT="${state_id_next}"
          export RATCHET_STEP_NEXT="${ratchet_step_next}"
          export STATE_CAP_NEXT="${state_cap}"
          export NET_CAP_NEXT="${net_cap}"
          export BUNDLE_REF="${bundle_ref}"
          export BUNDLE_HASH="${bundle_hash}"
          export EXPECTED_COMMIT_SHA="${{ inputs.expected_commit_sha }}"
          export ROUTE_MODE="${{ inputs.route_mode }}"

          python3 - <<'PY'
          import hashlib
          import json
          import os
          from pathlib import Path

          run_id = os.environ["RUN_ID"]
          state_id_next = os.environ["STATE_ID_NEXT"]
          ratchet_step_next = int(os.environ["RATCHET_STEP_NEXT"])
          state_cap_next = os.environ["STATE_CAP_NEXT"]
          net_cap_next = os.environ["NET_CAP_NEXT"]
          bundle_ref = os.environ["BUNDLE_REF"]
          bundle_hash = os.environ["BUNDLE_HASH"]
          expected_commit_sha = os.environ["EXPECTED_COMMIT_SHA"]
          repo = os.environ["GITHUB_REPOSITORY"]
          workflow_ref = f"{repo}/.github/workflows/swarm-live-run.yml@{expected_commit_sha}"
          timestamp = f"1970-01-01T00:00:{ratchet_step_next % 60:02d}Z"

          capability_meta = json.loads(Path("artifact/capability_meta.json").read_text(encoding="utf-8"))
          state_current = capability_meta.get("state_current", {})
          parent_state_id = state_current.get("state_id", "state-root")
          parent_ratchet_step = int(state_current.get("ratchet_step", 0))

          policy = {
              "schema_version": "agent_swarm-policy-v1",
              "policy_id": f"policy-{run_id}",
              "run_id": run_id,
              "route_mode": os.environ.get("ROUTE_MODE", "direct"),
              "source_backend": "artifact",
              "output_backend": "artifact",
              "workflow_ref": workflow_ref,
              "policy_generated_at": timestamp,
          }
          policy_bytes = json.dumps(policy, indent=2, sort_keys=True).encode("utf-8") + b"\n"
          Path("artifact/policy.json").write_bytes(policy_bytes)
          policy_hash = "sha256:" + hashlib.sha256(policy_bytes).hexdigest()

          certificate = {
              "type": "loom-agent-run-v1",
              "job_id": run_id,
              "request_hash": "sha256:" + hashlib.sha256(f"{run_id}::launch".encode("utf-8")).hexdigest(),
              "mode": "prompt-run",
              "parent_state": {
                  "state_id": parent_state_id,
                  "bundle_sha256": bundle_hash,
                  "ratchet_step": parent_ratchet_step,
              },
              "result": {
                  "response_sha256": "sha256:" + hashlib.sha256(f"{run_id}::response".encode("utf-8")).hexdigest(),
                  "response_locator": f"artifact://swarm-live-{run_id}/result.json",
                  "new_state": {
                      "state_id": state_id_next,
                      "bundle_sha256": bundle_hash,
                      "bundle_manifest_sha256": "sha256:" + hashlib.sha256(b"manifest-v1").hexdigest(),
                  },
              },
              "runtime": {
                  "workflow_ref": workflow_ref,
                  "runner_class": "github-hosted",
                  "started_at": timestamp,
                  "finished_at": timestamp,
              },
              "timestamp": timestamp,
              "policy": {
                  "schema_version": "agent_swarm-policy-v1",
                  "policy_hash": policy_hash,
                  "policy_ref": f"artifact://swarm-live-{run_id}/policy.json",
                  "policy_generated_at": timestamp,
              },
          }
          certificate_bytes = json.dumps(certificate, indent=2, sort_keys=True).encode("utf-8") + b"\n"
          Path("artifact/certificate.json").write_bytes(certificate_bytes)
          artifact_hash = "sha256:" + hashlib.sha256(certificate_bytes).hexdigest()

          result = {
              "run_id": run_id,
              "status": "succeeded",
              "operation": "launch",
              "node_id": f"github-node-{run_id}",
              "parent_node_id": "root",
              "state_id": state_id_next,
              "restore_mode": "checkpoint",
              "bundle_ref": bundle_ref,
              "bundle_sha256": bundle_hash,
              "certificate_ref": f"artifact://swarm-live-{run_id}/certificate.json",
              "artifact_hash": artifact_hash,
          }
          Path("artifact/result.json").write_bytes(
              json.dumps(result, indent=2, sort_keys=True).encode("utf-8") + b"\n"
          )

          next_tokens = {
              "state_cap_next": state_cap_next,
              "net_cap_next": net_cap_next,
              "state_id_next": state_id_next,
              "ratchet_step": ratchet_step_next,
          }
          Path("artifact/next_tokens.json").write_bytes(
              json.dumps(next_tokens, indent=2, sort_keys=True).encode("utf-8") + b"\n"
          )
          PY

      - name: Upload swarm artifacts
        uses: actions/upload-artifact@v4
        with:
          name: swarm-live-${{ inputs.request_id }}
          path: artifact/

      - name: Upload encrypted state bundle
        uses: actions/upload-artifact@v4
        with:
          name: state-bundle-${{ inputs.request_id }}
          path: artifact/state_bundle.tar.enc
